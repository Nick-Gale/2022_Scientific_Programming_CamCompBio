{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a248cf5a",
   "metadata": {},
   "source": [
    "## 1 Benchmarking and Profiling\n",
    "Assessing your own code can be very helpful. In general, there are two ways we want to do this: 1) Profiling: which gives us the opportunity to see our code structure, and 2) Benchmarking: which gives us the opportunity to assess our functions performance at runtime. We will start with Profiling.\n",
    "\n",
    "### 1.1 Profile\n",
    "Code profile is a feature offered by by many modern languages: there are excellent code profilers in R with the RStudio IDE and in MatLab. Profiling our code offers us the opportunity to pick up various errors in our code, get estimates for where our code is spending a lot of time, identify bottlenecks, and generally improve. Profiling in Julia is done through the ``@profile`` macro through the ``Profile`` package. A printout of the profile is given by ``Profile.print``. Let's write a simple function and profile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13ee3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c5c2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_func (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function my_func(n)\n",
    "    tmp = 0\n",
    "    for i = 1:n\n",
    "        tmp += rand()1. Benchmark Tools\n",
    "2. Profiling Tools\n",
    "\n",
    "\n",
    "    end\n",
    "    return tmp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b94183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overhead ╎ [+additional indent] Count File:Line; Function\n",
      "=========================================================\n",
      " ╎10 @Base/task.jl:484; (::IJulia.var\"#15#18\")()\n",
      " ╎ 10 @IJulia/src/eventloop.jl:8; eventloop(socket::ZMQ.Socket)\n",
      " ╎  10 @Base/essentials.jl:726; invokelatest\n",
      " ╎   10 @Base/essentials.jl:729; #invokelatest#2\n",
      " ╎    10 ...c/execute_request.jl:67; execute_request(socket::ZMQ.Sock...\n",
      " ╎     10 ...c/SoftGlobalScope.jl:65; softscope_include_string(m::Mod...\n",
      " ╎    ╎ 10 @Base/loading.jl:1428; include_string(mapexpr::typeof...\n",
      "8╎    ╎  10 @Base/boot.jl:368; eval\n",
      " ╎    ╎   2  ...piler/typeinfer.jl:996; typeinf_ext_toplevel(mi::Core...\n",
      " ╎    ╎    2  ...iler/typeinfer.jl:1000; typeinf_ext_toplevel(interp:...\n",
      " ╎    ╎     2  ...iler/typeinfer.jl:967; typeinf_ext(interp::Core.Com...\n",
      " ╎    ╎    ╎ 2  ...iler/typeinfer.jl:213; typeinf(interp::Core.Compil...\n",
      " ╎    ╎    ╎  2  ...iler/typeinfer.jl:230; _typeinf(interp::Core.Compi...\n",
      " ╎    ╎    ╎   2  ...nterpretation.jl:2462; typeinf_nocycle(interp::C...\n",
      " ╎    ╎    ╎    2  ...terpretation.jl:2366; typeinf_local(interp::Cor...\n",
      " ╎    ╎    ╎     2  ...terpretation.jl:1890; abstract_eval_statement(...\n",
      " ╎    ╎    ╎    ╎ 2  ...terpretation.jl:1733; abstract_call(interp::Co...\n",
      " ╎    ╎    ╎    ╎  2  ...erpretation.jl:1766; abstract_call(interp::C...\n",
      " ╎    ╎    ╎    ╎   2  ...erpretation.jl:1696; abstract_call_known(in...\n",
      " ╎    ╎    ╎    ╎    2  ...erpretation.jl:153; abstract_call_gf_by_ty...\n",
      " ╎    ╎    ╎    ╎     2  ...rpretation.jl:641; abstract_call_method(i...\n",
      " ╎    ╎    ╎    ╎    ╎ 2  .../typeinfer.jl:877; typeinf_edge(interp::...\n",
      " ╎    ╎    ╎    ╎    ╎  2  .../typeinfer.jl:213; typeinf(interp::Core....\n",
      " ╎    ╎    ╎    ╎    ╎   1  ...typeinfer.jl:230; _typeinf(interp::Cor...\n",
      " ╎    ╎    ╎    ╎    ╎    1  ...retation.jl:2462; typeinf_nocycle(int...\n",
      " ╎    ╎    ╎    ╎    ╎     1  ...retation.jl:2366; typeinf_local(inte...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎ 1  ...retation.jl:1890; abstract_eval_stat...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎  1  ...etation.jl:1733; abstract_call(int...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎   1  ...etation.jl:1766; abstract_call(in...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    1  ...tation.jl:1696; abstract_call_kn...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎     1  ...tation.jl:153; abstract_call_gf...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎ 1  ...tation.jl:641; abstract_call_m...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎  1  ...einfer.jl:877; typeinf_edge(in...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎   1  ...einfer.jl:213; typeinf(interp:...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    1  ...einfer.jl:230; _typeinf(interp...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎     1  ...tation.jl:2462; typeinf_nocycle...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ 1  ...tation.jl:2366; typeinf_local(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  1  ...tation.jl:1890; abstract_eval_s...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎   1  ...tation.jl:1733; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎    1  ...tation.jl:1766; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎     1  ...tation.jl:1696; abstract_call_k...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  +1 1  ...tation.jl:153; abstract_call_g...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  +2 1  ...tation.jl:641; abstract_call_m...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  +3 1  ...einfer.jl:877; typeinf_edge(in...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  +4 1  ...einfer.jl:213; typeinf(interp:...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  +5 1  ...einfer.jl:230; _typeinf(interp...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  +6 1  ...tation.jl:2462; typeinf_nocycle...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  +7 1  ...tation.jl:2366; typeinf_local(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  +8 1  ...tation.jl:1890; abstract_eval_s...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎  +9 1  ...tation.jl:1733; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +10 1  ...tation.jl:1766; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +11 1  ...tation.jl:1696; abstract_call_k...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +12 1  ...tation.jl:153; abstract_call_g...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +13 1  ...tation.jl:641; abstract_call_m...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +14 1  ...einfer.jl:877; typeinf_edge(in...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +15 1  ...einfer.jl:213; typeinf(interp:...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +16 1  ...einfer.jl:230; _typeinf(interp...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +17 1  ...tation.jl:2462; typeinf_nocycle...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +18 1  ...tation.jl:2366; typeinf_local(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +19 1  ...tation.jl:1890; abstract_eval_s...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +20 1  ...tation.jl:1733; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +21 1  ...tation.jl:1766; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +22 1  ...tation.jl:1696; abstract_call_k...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +23 1  ...tation.jl:153; abstract_call_g...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +24 1  ...tation.jl:641; abstract_call_m...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +25 1  ...einfer.jl:877; typeinf_edge(in...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +26 1  ...einfer.jl:213; typeinf(interp:...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +27 1  ...einfer.jl:230; _typeinf(interp...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +28 1  ...tation.jl:2462; typeinf_nocycle...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +29 1  ...tation.jl:2366; typeinf_local(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +30 1  ...tation.jl:1890; abstract_eval_s...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +31 1  ...tation.jl:1733; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +32 1  ...tation.jl:1766; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +33 1  ...tation.jl:1696; abstract_call_k...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +34 1  ...tation.jl:153; abstract_call_g...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +35 1  ...tation.jl:641; abstract_call_m...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +36 1  ...einfer.jl:877; typeinf_edge(in...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +37 1  ...einfer.jl:213; typeinf(interp:...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +38 1  ...einfer.jl:230; _typeinf(interp...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +39 1  ...tation.jl:2462; typeinf_nocycle...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +40 1  ...tation.jl:2366; typeinf_local(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +41 1  ...tation.jl:1890; abstract_eval_s...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +42 1  ...tation.jl:1733; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +43 1  ...tation.jl:1766; abstract_call(i...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +44 1  ...tation.jl:1696; abstract_call_k...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +45 1  ...tation.jl:153; abstract_call_g...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +46 1  ...tation.jl:641; abstract_call_m...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +47 1  ...einfer.jl:877; typeinf_edge(in...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +48 1  ...einfer.jl:213; typeinf(interp:...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +49 1  ...einfer.jl:257; _typeinf(interp...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +50 1  ...timize.jl:504; optimize\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +51 1  ...timize.jl:536; run_passes(ci::...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +52 1  ...timize.jl:645; slot2reg\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +53 1  ...ot2ssa.jl:907; construct_ssa!(...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +54 1  ...ot2ssa.jl:509; domsort_ssa!(ir...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +55 1  ...air/ir.jl:269; NewNodeStream\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +56 1  ...air/ir.jl:195; Core.Compiler.I...\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +57 1  .../array.jl:534; fill\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +58 1  .../array.jl:536; fill\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +59 1  ...e/boot.jl:468; Array\n",
      " ╎    ╎    ╎    ╎    ╎    ╎    ╎    ╎ +60 1  ...e/boot.jl:459; Array\n",
      " ╎    ╎    ╎    ╎    ╎   1  ...typeinfer.jl:277; _typeinf(interp::Cor...\n",
      " ╎    ╎    ╎    ╎    ╎    1  ...typeinfer.jl:395; cache_result!(inter...\n",
      " ╎    ╎    ╎    ╎    ╎     1  ...ypeinfer.jl:369; transform_result_fo...\n",
      "1╎    ╎    ╎    ╎    ╎    ╎ 1  ...ypeinfer.jl:349; maybe_compress_cod...\n",
      "Total snapshots: 11. Utilization: 100% across all threads and tasks. Use the `groupby` kwarg to break down by thread and/or task\n"
     ]
    }
   ],
   "source": [
    "@profile my_func(10)\n",
    "Profile.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00befcde",
   "metadata": {},
   "source": [
    "The standard output of the print function gives a nested tree dump. This can be very useful as we can visualise the function calls. It can be quite overwhelming and some people prefer it to be flattened. To do this we use the keyword ``format=:flat``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8e7f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count  Overhead File                    Line Function\n",
      " =====  ======== ====                    ==== ========\n",
      "     1         0 @Base/array.jl           534 fill\n",
      "     1         0 @Base/array.jl           536 fill\n",
      "     1         0 @Base/boot.jl            459 Array\n",
      "     1         0 @Base/boot.jl            468 Array\n",
      "    10         0 @Base/boot.jl            368 eval\n",
      "     2         0 ...ctinterpretation.jl  1733 abstract_call(interp::Core.Comp...\n",
      "     2         0 ...ctinterpretation.jl  1766 abstract_call(interp::Core.Comp...\n",
      "     2         0 ...ctinterpretation.jl   153 abstract_call_gf_by_type(interp...\n",
      "     2         0 ...ctinterpretation.jl  1696 abstract_call_known(interp::Cor...\n",
      "     2         0 ...ctinterpretation.jl   641 abstract_call_method(interp::Co...\n",
      "     2         0 ...ctinterpretation.jl  1890 abstract_eval_statement(interp:...\n",
      "     2         0 ...ctinterpretation.jl  2366 typeinf_local(interp::Core.Comp...\n",
      "     2         0 ...ctinterpretation.jl  2462 typeinf_nocycle(interp::Core.Co...\n",
      "     1         0 ...ompiler/optimize.jl   504 optimize\n",
      "     1         0 ...ompiler/optimize.jl   536 run_passes(ci::Core.CodeInfo, s...\n",
      "     1         0 ...ompiler/optimize.jl   645 slot2reg\n",
      "     1         0 ...ompiler/ssair/ir.jl   195 Core.Compiler.InstructionStream...\n",
      "     1         0 ...ompiler/ssair/ir.jl   269 NewNodeStream\n",
      "     1         0 ...r/ssair/slot2ssa.jl   907 construct_ssa!(ci::Core.CodeInf...\n",
      "     1         0 ...r/ssair/slot2ssa.jl   509 domsort_ssa!(ir::Core.Compiler....\n",
      "     2         0 ...mpiler/typeinfer.jl   230 _typeinf(interp::Core.Compiler....\n",
      "     1         0 ...mpiler/typeinfer.jl   257 _typeinf(interp::Core.Compiler....\n",
      "     1         0 ...mpiler/typeinfer.jl   277 _typeinf(interp::Core.Compiler....\n",
      "     1         0 ...mpiler/typeinfer.jl   395 cache_result!(interp::Core.Comp...\n",
      "     1         0 ...mpiler/typeinfer.jl   349 maybe_compress_codeinfo(interp:...\n",
      "     1         0 ...mpiler/typeinfer.jl   369 transform_result_for_cache\n",
      "     2         0 ...mpiler/typeinfer.jl   213 typeinf(interp::Core.Compiler.N...\n",
      "     2         0 ...mpiler/typeinfer.jl   877 typeinf_edge(interp::Core.Compi...\n",
      "     2         0 ...mpiler/typeinfer.jl   967 typeinf_ext(interp::Core.Compil...\n",
      "     2         0 ...mpiler/typeinfer.jl   996 typeinf_ext_toplevel(mi::Core.M...\n",
      "     2         0 ...mpiler/typeinfer.jl  1000 typeinf_ext_toplevel(interp::Co...\n",
      "    10         0 @Base/essentials.jl      729 #invokelatest#2\n",
      "    10         0 @Base/essentials.jl      726 invokelatest\n",
      "    10         0 @Base/loading.jl        1428 include_string(mapexpr::typeof(...\n",
      "    10        10 @Base/task.jl            484 (::IJulia.var\"#15#18\")()\n",
      "    10         0 ...ia/src/eventloop.jl     8 eventloop(socket::ZMQ.Socket)\n",
      "    10         0 .../execute_request.jl    67 execute_request(socket::ZMQ.Soc...\n",
      "    10         0 .../SoftGlobalScope.jl    65 softscope_include_string(m::Mod...\n",
      "Total snapshots: 11 (100% utilization across all threads and tasks. Use the `groupby` kwarg to break down by thread and/or task)\n"
     ]
    }
   ],
   "source": [
    "Profile.print(format=:flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea6537",
   "metadata": {},
   "source": [
    "This is not a particularly complicated function. Let's write something that might be a little more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0029f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matwork (generic function with 2 methods)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fsum(x)\n",
    "    v = zeros(length(x))\n",
    "    for i = 1:length(x)\n",
    "        for j = 1:i\n",
    "            v[i] += abs(sqrt.(x[i] + x[j]))\n",
    "        end\n",
    "    end    \n",
    "    return v\n",
    "end\n",
    "\n",
    "function matwork(A::Array{Float64, 2})\n",
    "    sz = size(A)\n",
    "    for j = 1:sz[2]\n",
    "        for i = 1:sz[2]\n",
    "            new_vec = A[:,j]\n",
    "            temp_vec = fsum(new_vec)\n",
    "            A[i, :] .+= temp_vec\n",
    "        end\n",
    "    end\n",
    "    return A\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbc59a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.782220 seconds (120.00 k allocations: 206.909 MiB, 1.22% gc time)\n"
     ]
    }
   ],
   "source": [
    "A = rand(200, 200)\n",
    "@time matwork(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f30d37",
   "metadata": {},
   "source": [
    "That was quite a complicated function, but several seconds seems very long to handle a measly 200x200 matrix. Wasn't Julia meant to be quick?! This is an ideal time to profile our code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33ee9052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count  Overhead File                    Line Function\n",
      " =====  ======== ====                    ==== ========\n",
      "     1         0 @Base/int.jl              83 <\n",
      "     1         0 @Base/simdloop.jl         75 macro expansion\n",
      "     1         0 @Base/promotion.jl       477 ==\n",
      "     1         0 @Base/range.jl           883 iterate\n",
      "     1         0 ...multidimensional.jl   904 macro expansion\n",
      "     1         0 ...multidimensional.jl   901 macro expansion\n",
      "     1         0 @Base/subarray.jl        341 setindex!\n",
      "     1         0 @Base/broadcast.jl       961 macro expansion\n",
      "     1         0 @Base/simdloop.jl         77 macro expansion\n",
      "     2         0 @Base/broadcast.jl       960 copyto!\n",
      "     2         0 @Base/broadcast.jl       913 copyto!\n",
      "     2         0 @Base/broadcast.jl       871 materialize!\n",
      "     2         0 @Base/broadcast.jl       868 materialize!\n",
      "     5         0 @Base/array.jl           924 getindex\n",
      "     5         0 @Base/float.jl           383 +\n",
      "     7         0 @Base/array.jl           588 zeros\n",
      "     7         0 @Base/array.jl           353 fill!\n",
      "     7         0 @Base/array.jl           589 zeros\n",
      "     7         0 @Base/math.jl            592 sqrt\n",
      "     7         0 @Base/broadcast.jl       670 _broadcast_getindex_evalf\n",
      "     7         0 @Base/broadcast.jl       643 _broadcast_getindex\n",
      "     7         0 @Base/broadcast.jl       597 getindex\n",
      "     7         0 @Base/broadcast.jl       875 copy\n",
      "     7         0 @Base/broadcast.jl       860 materialize\n",
      "    14         0 @Base/array.jl           585 zeros\n",
      "    14         0 @Base/array.jl           583 zeros\n",
      "    14         0 In[27]                     2 fsum(x::Vector{Float64})\n",
      "    15         0 @Base/array.jl           378 similar\n",
      "    15         0 @Base/abstractarray.jl   795 similar\n",
      "    15         0 ...multidimensional.jl   887 _unsafe_getindex\n",
      "    17         0 In[27]                    17 matwork(A::Matrix{Float64})\n",
      "    19         0 ...multidimensional.jl   903 macro expansion\n",
      "    21         0 In[27]                    15 matwork(A::Matrix{Float64})\n",
      "    21         0 @Base/cartesian.jl        64 macro expansion\n",
      "    21         0 ...multidimensional.jl   898 _unsafe_getindex!\n",
      "    21         0 ...multidimensional.jl   889 _unsafe_getindex\n",
      "    22         0 @Base/boot.jl            459 Array\n",
      "    22         0 @Base/boot.jl            468 Array\n",
      "    36         0 ...multidimensional.jl   875 _getindex\n",
      "    36         0 @Base/abstractarray.jl  1241 getindex\n",
      "   391         0 In[27]                     5 fsum(x::Vector{Float64})\n",
      "   401         0 @Base/array.jl           966 setindex!\n",
      "  1337         0 In[27]                     6 fsum(x::Vector{Float64})\n",
      "  1742         0 In[27]                    16 matwork(A::Matrix{Float64})\n",
      "  1781      1781 @Base/task.jl            484 (::IJulia.var\"#15#18\")()\n",
      "  1781         0 @Base/essentials.jl      729 #invokelatest#2\n",
      "  1781         0 @Base/essentials.jl      726 invokelatest\n",
      "  1781         0 ...ia/src/eventloop.jl     8 eventloop(socket::ZMQ.Socket)\n",
      "  1781         0 .../execute_request.jl    67 execute_request(socket::ZMQ.Soc...\n",
      "  1781         0 .../SoftGlobalScope.jl    65 softscope_include_string(m::Mod...\n",
      "  1781         0 @Base/boot.jl            368 eval\n",
      "  1781         0 @Base/loading.jl        1428 include_string(mapexpr::typeof(...\n",
      "Total snapshots: 1781 (100% utilization across all threads and tasks. Use the `groupby` kwarg to break down by thread and/or task)\n"
     ]
    }
   ],
   "source": [
    "Profile.clear()\n",
    "@profile matwork(A)\n",
    "Profile.print(format=:flat, sortedby=:count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c8b640",
   "metadata": {},
   "source": [
    "There seems to a lot of calls in ``fsum`` and many calls to materialise. What is going on? On closer inspection it seems that we calling ``fsum`` for every value of ``i`` but it accepts inputs that change only dependent on ``j``. On top of that we allocate a new vector every time we do this! That is a lot of wasted computation! Let's fix these things and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82f7aef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matwork_prof (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fsum_prof(x)\n",
    "    v = zeros(length(x))\n",
    "    for i = 1:length(x)\n",
    "        for j = 1:i\n",
    "            v[i] += abs(sqrt.(x[i] + x[j]))\n",
    "        end\n",
    "    end    \n",
    "    return v\n",
    "end\n",
    "\n",
    "function matwork_prof(A::Array{Float64, 2})\n",
    "    sz = size(A)\n",
    "    temp_vec = zeros(sz[2])\n",
    "    for j = 1:sz[2]\n",
    "        temp_vec .= fsum(A[:,j])\n",
    "        for i = 1:sz[2]\n",
    "            A[i, :] .+= temp_vec\n",
    "        end\n",
    "    end\n",
    "    return A\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c448b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count  Overhead File                    Line Function\n",
      " =====  ======== ====                    ==== ========\n",
      "     1         0 In[27]                     5 fsum(x::Vector{Float64})\n",
      "     1         0 @Base/subarray.jl        341 setindex!\n",
      "     1         0 @Base/indices.jl         367 iterate\n",
      "     1         0 ...multidimensional.jl   904 macro expansion\n",
      "     1         0 @Base/float.jl           383 +\n",
      "     1         0 @Base/broadcast.jl       670 _broadcast_getindex_evalf\n",
      "     1         0 @Base/broadcast.jl       643 _broadcast_getindex\n",
      "     1         0 @Base/broadcast.jl       597 getindex\n",
      "     1         0 ...mpiler/typeinfer.jl   277 _typeinf(interp::Core.Compiler....\n",
      "     1         0 ...mpiler/typeinfer.jl   369 transform_result_for_cache\n",
      "     1         0 ...mpiler/typeinfer.jl   395 cache_result!(interp::Core.Comp...\n",
      "     1         0 ...mpiler/typeinfer.jl   349 maybe_compress_codeinfo(interp:...\n",
      "     1         0 ...ompiler/optimize.jl   541 run_passes(ci::Core.CodeInfo, s...\n",
      "     1         0 ...ompiler/ssair/ir.jl   917 renumber_ssa2!(stmt::Any, ssanu...\n",
      "     1         0 ...ompiler/ssair/ir.jl   467 iterate(it::Core.Compiler.UseRe...\n",
      "     1         0 ...mpiler/typeinfer.jl   230 _typeinf(interp::Core.Compiler....\n",
      "     1         0 ...ctinterpretation.jl  2462 typeinf_nocycle(interp::Core.Co...\n",
      "     1         0 ...ctinterpretation.jl  2340 typeinf_local(interp::Core.Comp...\n",
      "     1         0 ...ctinterpretation.jl  1890 abstract_eval_statement(interp:...\n",
      "     1         0 ...ctinterpretation.jl  1733 abstract_call(interp::Core.Comp...\n",
      "     1         0 ...ctinterpretation.jl  1766 abstract_call(interp::Core.Comp...\n",
      "     1         0 ...ctinterpretation.jl  1696 abstract_call_known(interp::Cor...\n",
      "     1         0 ...ctinterpretation.jl   162 abstract_call_gf_by_type(interp...\n",
      "     1         0 ...ctinterpretation.jl   850 abstract_call_method_with_const...\n",
      "     1         0 ...ompiler/optimize.jl   545 run_passes(ci::Core.CodeInfo, s...\n",
      "     2         0 @Base/cartesian.jl        66 macro expansion\n",
      "     2         0 @Base/broadcast.jl       961 macro expansion\n",
      "     2         0 @Base/simdloop.jl         77 macro expansion\n",
      "     2         0 @Base/broadcast.jl       960 copyto!\n",
      "     2         0 @Base/broadcast.jl       913 copyto!\n",
      "     2         0 @Base/broadcast.jl       871 materialize!\n",
      "     2         0 @Base/broadcast.jl       868 materialize!\n",
      "     2         0 @Base/promotion.jl       477 ==\n",
      "     2         0 @Base/range.jl           883 iterate\n",
      "     2         0 ...ompiler/optimize.jl   504 optimize\n",
      "     2         0 ...mpiler/typeinfer.jl   257 _typeinf(interp::Core.Compiler....\n",
      "     2         0 ...ompiler/ssair/ir.jl  1459 compact!\n",
      "     2         0 ...ompiler/ssair/ir.jl  1461 compact!(code::Core.Compiler.IR...\n",
      "     2         0 ...ompiler/ssair/ir.jl  1308 iterate(compact::Core.Compiler....\n",
      "     2         0 ...ompiler/ssair/ir.jl  1036 process_node!(compact::Core.Com...\n",
      "     3         0 ...mpiler/typeinfer.jl   996 typeinf_ext_toplevel(mi::Core.M...\n",
      "     3         0 ...mpiler/typeinfer.jl  1000 typeinf_ext_toplevel(interp::Co...\n",
      "     3         0 ...mpiler/typeinfer.jl   967 typeinf_ext(interp::Core.Compil...\n",
      "     3         0 ...mpiler/typeinfer.jl   213 typeinf(interp::Core.Compiler.N...\n",
      "     6         0 @Base/boot.jl            459 Array\n",
      "     6         0 @Base/boot.jl            468 Array\n",
      "     6         0 @Base/array.jl           378 similar\n",
      "     6         0 @Base/abstractarray.jl   795 similar\n",
      "     6         0 ...multidimensional.jl   887 _unsafe_getindex\n",
      "     7         0 In[27]                     6 fsum(x::Vector{Float64})\n",
      "     8         0 ...multidimensional.jl   903 macro expansion\n",
      "     8         0 In[37]                    15 matwork_prof(A::Matrix{Float64})\n",
      "     9         0 @Base/cartesian.jl        64 macro expansion\n",
      "    10         0 @Base/array.jl           966 setindex!\n",
      "    11         0 ...multidimensional.jl   898 _unsafe_getindex!\n",
      "    11         0 ...multidimensional.jl   889 _unsafe_getindex\n",
      "    17         0 ...multidimensional.jl   875 _getindex\n",
      "    17         0 @Base/abstractarray.jl  1241 getindex\n",
      "    19         0 In[37]                    17 matwork_prof(A::Matrix{Float64})\n",
      "    72        72 @Base/task.jl            484 (::IJulia.var\"#15#18\")()\n",
      "    72         0 @Base/essentials.jl      729 #invokelatest#2\n",
      "    72         0 @Base/essentials.jl      726 invokelatest\n",
      "    72         0 ...ia/src/eventloop.jl     8 eventloop(socket::ZMQ.Socket)\n",
      "    72         0 .../execute_request.jl    67 execute_request(socket::ZMQ.Soc...\n",
      "    72         0 .../SoftGlobalScope.jl    65 softscope_include_string(m::Mod...\n",
      "    72         0 @Base/boot.jl            368 eval\n",
      "    72         0 @Base/loading.jl        1428 include_string(mapexpr::typeof(...\n",
      "Total snapshots: 82 (100% utilization across all threads and tasks. Use the `groupby` kwarg to break down by thread and/or task)\n"
     ]
    }
   ],
   "source": [
    "Profile.clear()\n",
    "@profile matwork_prof(A);\n",
    "Profile.print(format=:flat, sortedby=:count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4aa16",
   "metadata": {},
   "source": [
    "That is certainly looking a lot cleaner! We have gotten rid of almost all the materialise calls and reduced the amount of time spent in ``fsum``. It would be reasonable to suspect that this function runs a lot faster! Let's confirm those suspicions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82f1cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.030715 seconds (40.40 k allocations: 69.661 MiB, 8.04% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time matwork_prof(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d776631",
   "metadata": {},
   "source": [
    "That's much better! Profiling can be complicated but is a very powerful tool!\n",
    "\n",
    "### 1.2 Benchmarking\n",
    "\n",
    "Another powerful tool we have to evaluate our code performance is benchmarking which can tell us about time, allocation, and memory requirements of our program. This might seem odd because we already have the ``@time`` and ``@elapsed`` macros which tell us the wall time. These are useful, but they can change based on specifics of the function call, what else the computer is doing at the time, how much memory has been allocated and required, and a host of other factors. It is better to run a series of function calls and examine the statistics of these runs. For this we use the ``BenchmarkTools`` package with ``@benchmark`` macro. It gives us a lot of information including the estimated memory required for the program and the time spent in garbage collection (freeing up unused memory). To properly benchmark we want to interpolate any symbols that we don't want to be included in the calculation with a ``$``; generally this means variables like our ``A`` matrix but we can find more details in the [documentation](https://github.com/JuliaCI/BenchmarkTools.jl). Let's try it out on our two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "586f7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "367ef879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 3 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.743 s\u001b[22m\u001b[39m … \u001b[35m 1.762 s\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.33% … 0.26%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.753 s             \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.33%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.753 s\u001b[22m\u001b[39m ± \u001b[32m9.528 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.31% ± 0.04%\n",
       "\n",
       "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m \u001b[39m \n",
       "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[32m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m \u001b[39m▁\n",
       "  1.74 s\u001b[90m        Histogram: frequency by time\u001b[39m        1.76 s \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m206.91 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m120000\u001b[39m."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark matwork($A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b466f4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 214 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m22.332 ms\u001b[22m\u001b[39m … \u001b[35m 33.266 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m5.26% … 3.50%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m23.744 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m9.91%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m23.411 ms\u001b[22m\u001b[39m ± \u001b[32m934.233 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m8.04% ± 2.31%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m▇\u001b[39m▁\u001b[39m▃\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[34m▂\u001b[39m\u001b[39m▃\u001b[39m▂\u001b[39m▅\u001b[39m▄\u001b[39m█\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m▄\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▅\u001b[39m▁\u001b[39m▇\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▁\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▃\u001b[39m▅\u001b[39m▁\u001b[39m▄\u001b[39m \u001b[39m▄\n",
       "  22.3 ms\u001b[90m         Histogram: frequency by time\u001b[39m         24.2 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m69.66 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m40401\u001b[39m."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark matwork_prof($A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ebe00",
   "metadata": {},
   "source": [
    "Immediately, we can see that something is quite off with the first function. It has vastly higher memory and allocation requirements and somehow spends less time (percentage wise) in garbage collection. This might lead us to supsect the problems we found by profiling fairly quickly. The ``BenchmarkTools`` also provides the ``@btime`` and ``@belapsed`` macros as benchmarked analogues to the ``@time`` and ``@elapsed`` macros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326844a",
   "metadata": {},
   "source": [
    "## 2 Advanced Workflow: Modules, Revise, and Environments\n",
    "\n",
    "Hopefully by now you have had the chance to interact with notebooks, the REPL, and even will have written your own scripts. Scripts are useful because they don't require you to remember the code commands that you entered, or force you to execute multiple cells. You may find, however, that you are writing multiple scripts which recycle functions or your scripts are getting very long with multiple function definitions that are necessary, but greatly distract from readability. In this case you might want to write a Module.\n",
    "\n",
    "### 2.1 Modules\n",
    "A Module in Julia is a file that is a code block using the keyword ``module ModuleName`` and functions similarly to a package. It can store multiple local definitions and export a select few using the ``export`` keyword. When the file is included into a workspace the exported function definitions can be added with the ``using`` keyword and the \"package\" name is the module name appended to ``Main`` or prepended with a dot i.e. ``using Main.ModuleName`` or ``using .ModuleName``. Let's create a simple module that exports some basic statistical functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d994ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.SimpleStats"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module SimpleStats\n",
    "    # let's specifiy the functions we want to export\n",
    "    export average\n",
    "    export sdev\n",
    "\n",
    "    # let's define the functions in the module\n",
    "    function average(x::Vector{Float64})\n",
    "        tot = sum(x)\n",
    "        L = length(x)\n",
    "        return tot/L\n",
    "    end\n",
    "\n",
    "    function variance(x::Vector{Float64})\n",
    "        sqdiff = (x .- average(x)) .^2\n",
    "        L = length(x)\n",
    "        return sum(sqdiff/L)\n",
    "    end\n",
    "\n",
    "    function sdev(x::Vector{Float64})\n",
    "        return sqrt(variance(x))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066aea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using .SimpleStats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3da08",
   "metadata": {},
   "source": [
    "Now that we have included the Module we can access exported functions in the regular fashion for accessing from packages. Importantly, we cannot access non-exported functions even though exported functions may depend on them. To access functions inside the Module (or package) that have not been exported we need to use the Module identifier (name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b2a1cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.513284049739063"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(100);\n",
    "\n",
    "average(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98447a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2852750103932654"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleStats.sdev(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d9df6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: variance not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: variance not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[5]:1",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "variance(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dacf193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08138183155487769"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleStats.variance(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0f4dab",
   "metadata": {},
   "source": [
    "### 2.2 Revise Workflow\n",
    "\n",
    "Often we find ourselves first in a notebook, or the REPL, working on some project. It then becomes sufficiently large or sufficiently well defined that we migrate to a script which we execute in the REPL using the code ``include(\"path/to/script.jl\")``. Eventually, we find that we are reusing a lot of functions in the script and they have many dependencies on each other which are distracting us from the main problem. We then move these functions into a module file using the structure defined above. Now we include the module file using the command ``include(\"path/to/module.jl\")`` and in our script we include the line ``using .ModuleName``. This works great the first time we do it! Let's try and include a module file in the resources directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa8060de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.OurModule"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"resources/testmodule.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcf3f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using .OurModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87b488cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the modules print function\n",
      "nothing\n",
      "This is the modules print function\n",
      "nothing\n",
      "This is the modules print function\n",
      "nothing\n"
     ]
    }
   ],
   "source": [
    "module_function(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c42fb",
   "metadata": {},
   "source": [
    "That's a pretty useless function! Let's go to the file and edit the module function to print the first ``n`` squares. After we are done, we will save the file and try and run it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56127be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the modules print function\n",
      "nothing\n",
      "This is the modules print function\n",
      "nothing\n",
      "This is the modules print function\n",
      "nothing\n"
     ]
    }
   ],
   "source": [
    "module_function(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7958c5",
   "metadata": {},
   "source": [
    "Nothing happened. We could include the module file again and import all the functions. However, this would result in a naming conflict! We could also abort the Julia session and reload everything, but this would incur the large precompilation times and its not really how we like to script in Julia. To get around this problem we use the ``Revise`` package. The ``Revise`` package lets us track changes in a file and immediately loads in the new changes making it ideal for scripting and working on a module (or any file, really) simulatenously. To track a file we use the function ``includet('path/to/file')``. Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f4d80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "includet(\"resources/testmodule.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ec7be",
   "metadata": {},
   "source": [
    "Now go back and edit the file again. Save it and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2d15441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "module_function(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651f116",
   "metadata": {},
   "source": [
    "That's much better!\n",
    "\n",
    "### 2.3 Environments\n",
    "\n",
    "An environment is an excellent way to manage code. It allows us to create mini-packages (or large ones) that can be exported later. The easiest way to do this is to nagivate to the directory level you want to create a package in, enter the package manager using ``]`` and type the code ``generate PackageName`` where PackageName is the name of the package. This will generate a Project file, Manifest file, and an src folder with the module in it. Activating the package may done by navigating to the ``dir/PackageName`` directory and in terminal typing ``julia --project=.``. Alternatively, in the package manager with ``activate .``. Now, any packages that are added in the package manager will be added and precompiled into this package and the version saved so that we wont have any dependencies moving forward. Furthermore, we can use this package (and all the functions in the src/PackageName) file by the command ``using PackageName``. Notice that there is now no dot or reference to ``Main``. Finally, Revise will apply to all files in this directory so we can file manage how we wish with functions spread over multiple directories and files. Once activated, this environment behaves precisely like a normal package making it ideal for use with Git and regular package development mindsets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4203d82",
   "metadata": {},
   "source": [
    "## 3 Advanced Types:\n",
    "In the previous section we covered some basic types that we might expect to see. These included primitives such as Float32 and Int64, Arrays such as Array{::Type,dim} and their aliases Vector{::Type} and Matrix{::Type}, and some more abstract types such as Array{Array{::Type, dimx},dimn}. We also learnt some common construction methods for intialising and inputing data. All of these where, hopefully, quite intuitive. Julia's basic types are very mathematically inclined and we likely had some notion of them going into the exercise.\n",
    "\n",
    "### 3.1 Composite Types\n",
    "Suppose that we wanted to create our own custom type. In Julia this is known as a *composite type*. A composite type is essentially just a collection of field and is called an object in other programming language. To create them in Julia we use the ``struct`` keyword. Let's work with something that we are already familiar with and create our own composite type for complex number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95caf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct CustomComplex\n",
    "    real::Float64\n",
    "    imag::Float64\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd575d7",
   "metadata": {},
   "source": [
    "To use our type we simply need to instantiate objects called as a function. Note that we insisted real have the primitive type ``::Float64`` and any number we use will be promoted to this type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beba924d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomComplex(1.2, 1.3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = CustomComplex(1.2, 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b596ec25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe1fa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomComplex(1.0, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = CustomComplex(1f0, 1f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c94c4a",
   "metadata": {},
   "source": [
    "We can begin to make custom functions that operate specifically on our types. This may seem superfluous at first because we can do this all with arrays and indexing. It does however provide a certain level of abstraction to your code. Supposing that you have a certain type with its own algebra or special operation rules, defining it explicitly and giving it a special set of functions allows you to abstract away the code and think in terms of the more natural algebra or ruleset asscociated with it. Imagine if we had to use ``mod`` and ``for`` for *every* matrix operation we did. Defining a function to operate on a composite type is as easy as any other type in Julia. Let's write a modulus function for our ``CustomComplex`` type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74ff2a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_modulus (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_modulus(x::CustomComplex) = (x.real^2 + x.imag^2)^0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092b8623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7691806012954132"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_modulus(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c25a962",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching custom_modulus(::Complex{Int64})\n\u001b[0mClosest candidates are:\n\u001b[0m  custom_modulus(\u001b[91m::CustomComplex\u001b[39m) at In[11]:1",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching custom_modulus(::Complex{Int64})\n\u001b[0mClosest candidates are:\n\u001b[0m  custom_modulus(\u001b[91m::CustomComplex\u001b[39m) at In[11]:1",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[13]:1",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "custom_modulus(1 + 1im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b299403",
   "metadata": {},
   "source": [
    "### 3.2 Custom Construction Methods\n",
    "\n",
    "It can be useful for numbers to instantiate types by simply typing in their fields. However, for more complicated types it can be useful to define a constructor method. The type name itself is already a constructor method but to make it more generic we add a function inside the structure and call the ``new`` function to fill the fields. For example, suppose that we want to have a type that tells us the mean and variance of a sample of a distribution. We really only want to feed it one number, the number of samples. Then, we want something to happen in the background and we are given the mean and variance. Let's use a composite type ``MyStats`` to perform this task on the uniform distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1df8e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SimpleUniformStats\n",
    "    mean\n",
    "    variance\n",
    "    function SimpleUniformStats(n::Int)\n",
    "        sample = rand(n)\n",
    "        av = average(sample)\n",
    "        std = sdev(sample)\n",
    "        var = std^2\n",
    "        new(av, var)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0dbed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first trial returned mean and variance: [0.4835818903105731, 0.08600805875562724]\n"
     ]
    }
   ],
   "source": [
    "trial1 = SimpleUniformStats(100)\n",
    "println(\"The first trial returned mean and variance: $([trial1.mean, trial1.variance])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a12ab0",
   "metadata": {},
   "source": [
    "### 3.4 Mutable Types\n",
    "Composite types are immutable: we can't change the fields of the object once they are set. Sometimes we would like our types to have mutable properties and behave like objects that can be modified. There are differences in allocation between mutable and immutable types but we wont worry about these: focus on what is most appropriate to make code *understandable* before *performant*. Let's suppose that we want to create an object that can be modified e.g. the location of a cell centre in a frame with multiple cells. Each cell could be idenitified with its own object and the object updated frame-by-frame in a video. To do this we use the ``mutable`` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93495962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellCentre(0.0f0, 0.0f0, 0.0f0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct CellCentre\n",
    "    x::Float32\n",
    "    y::Float32\n",
    "    z::Float32\n",
    "end\n",
    "\n",
    "cell1 = CellCentre(0, 0, 0)\n",
    "cell2 = CellCentre(0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acc4a8f",
   "metadata": {},
   "source": [
    "Now we can try mutating it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd08d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellCentre(1.0f0, 0.0f0, 0.0f0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell1.x = 1.0\n",
    "cell1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77e7a9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At time t = 1.0: Cell 1 [1.0, 1.0, 2.0] || Cell 2 [2.0, 1.0, 0.5]  0.9801, 0.495] \r"
     ]
    }
   ],
   "source": [
    "for t = 0:0.01:1\n",
    "    cell1.x = round(t, digits=2)\n",
    "    cell1.y = t^2\n",
    "    cell1.z = t^3 + t^2\n",
    "    \n",
    "    cell2.x = t + 1\n",
    "    cell2.y = t^2\n",
    "    cell2.z = 0.5 * t\n",
    "    print(\"At time t = $t: Cell 1 [$(cell1.x), $(cell1.y), $(cell1.z)] || Cell 2 [$(cell2.x), $(cell2.y), $(cell2.z)] \\r\")\n",
    "    sleep(0.1)\n",
    "    flush(stdout) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11499187",
   "metadata": {},
   "source": [
    "Occasionally, we want to mutate only part of the mutable structure. To do this we specify which fields are constant with the ``const`` keyword. Let's return to our statistical example. We may want to make a note if the mean and standard deviation look perculiar for a particular sample. Let's write a mutable structure that allows for this without changing the actual measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e38439e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotableUniformStats(0.4212730892135467, 0.29922504148515366, 10, \"This looks fine.\")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct NotableUniformStats\n",
    "    const mean\n",
    "    const std\n",
    "    const sample_size\n",
    "    note::String\n",
    "    function NotableUniformStats(n::Int)\n",
    "        sample = rand(n)\n",
    "        av = average(sample)\n",
    "        std = sdev(sample)\n",
    "        new(av, std, n, \"\")\n",
    "    end\n",
    "end\n",
    "\n",
    "simpleSample = NotableUniformStats(10);\n",
    "simpleSample.note = \"This looks fine.\";\n",
    "simpleSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "224c8a67",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "setfield!: const field .mean of type NotableUniformStats cannot be changed",
     "output_type": "error",
     "traceback": [
      "setfield!: const field .mean of type NotableUniformStats cannot be changed",
      "",
      "Stacktrace:",
      " [1] setproperty!(x::NotableUniformStats, f::Symbol, v::Int64)",
      "   @ Base ./Base.jl:39",
      " [2] top-level scope",
      "   @ In[30]:1",
      " [3] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "simpleSample.mean = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b05bd01",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: NotableUniformStats not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: NotableUniformStats not defined",
      "",
      "Stacktrace:",
      " [1] (::var\"#1#2\")(i::Int64)",
      "   @ Main ./none:0",
      " [2] iterate",
      "   @ ./generator.jl:47 [inlined]",
      " [3] collect(itr::Base.Generator{UnitRange{Int64}, var\"#1#2\"})",
      "   @ Base ./array.jl:787",
      " [4] top-level scope",
      "   @ In[1]:1",
      " [5] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [6] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "samples = [NotableUniformStats(rand(1000:10000)) for i = 1:200]\n",
    "\n",
    "fishy_indexes = Int64[]\n",
    "for i = 1:length(samples)\n",
    "    if abs((samples[i].mean - 0.5) / (samples[i].std / sqrt(samples[i].sample_size))) > 1.96\n",
    "        append!(fishy_indexes, i)\n",
    "        samples[i].note = \"This sample is fishy at the 95% confidence interval. The sample size is $(samples[i].sample_size)).\"\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"There are $(length(odd_indexes)) fishy samples\")\n",
    "for i in fishy_indexes\n",
    "    println(samples[i].note)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4763e",
   "metadata": {},
   "source": [
    "### 3.5 AutoDifferentiation: A useful example\n",
    "\n",
    "So far our types have been rather contrived and it would be difficult to see a use case for them outside of this notebook. This convenient type system and Julia's remarkable baseline performance has set us up to code something very wonderful: an auto-differentation system.\n",
    "\n",
    "As a reminder: the derivative of a function $f(x)$ is defined as $ f^{\\prime}(x) = \\lim_{h\\rightarrow0} \\frac{f(x + h) - f(x)}{h} $. We might remember this definition from high school and remember drawing tangent lines to the curve of $f(x) = x^2$ for ever smaller $h$ to convince ourselves that $f'(x) = 2x$. That useful exercise is actually precisely how we calculated derivates that we didn't know numerically and this is known as *numerical differentiation*. A numerical differentation routine might look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc39e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df(f, x, h) = (f.(x .+ h) .- f.(x)) ./ h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a8c6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "2.100000000000002\n",
      "2.0100000000000002\n",
      "2.0009999999996975\n",
      "2.000099999999172\n"
     ]
    }
   ],
   "source": [
    "for p = 0:-1:-4\n",
    "    h = 10.0^p\n",
    "    println(df(x -> x^2, 1, h))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a0557",
   "metadata": {},
   "source": [
    "That looks pretty good. We are certainly getting closer and closer to the correct answer. Furthemore, the function will clearly generalise to all broadcastable functions ``f``. \n",
    "\n",
    "However, we clearly desire some level of precision (taking ``h = 1`` is simply too inaccurate!). How do we choose which precision we need and wouldn't it be better to have it at the same precision as our function call so that we dont have to worry about numerical instability? Well, we can certainly have it at arbitrary precision, we already know the derivative. We could just hard-code $ df(x) = 2x $. This is known as *symbolic* differentation. It is employed extensively in Computer Algebra Systems such as Mathematica and Maple. However, this can also be slow as with complicated functions they need to apply a long list of rules to reduce the symbols to their final form. The amount of symbols can also blow up making this an unfeasible option.\n",
    "\n",
    "However, almost all functions we deal with (however complicated) are typically just compositions of a few simple primitive functions. We know the differentation rules for these simple types and we also know how to deal with compositions using the Chain rule! It feels as though we can design an algebra around these. Let's consider the Taylor series of a function $f$:\n",
    "\n",
    "$f(x+h) = f(x) + hf^\\prime(x) + h^2f^{\\prime \\prime}(x) + ...$\n",
    "\n",
    "we know that when the $h$ becomes very small we can disregard all the higher terms $h^2$ and above because these will have virtually no contribution. However, $h$ itself is infitesimally small (just above 0) so why don't we consider it to be it's own new special type of number. Now let's look at the Taylor series again we have an $x + h$ and a $f(x) + hf^\\prime(x)$ so these both take the form of this new type of number. This looks like a good candidate for a new type! Let's define our type ``Dual`` with two fields: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f37135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Dual <: Number\n",
    "    n::Float64 # the regular number\n",
    "    d::Float64 # the infinitesimal number \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf12ff35",
   "metadata": {},
   "source": [
    "We also want to make sure that our Duals work well with other numbers. Therefore we are going to define the promote rule to promote any numbers to Duals when required, and extend the convert rule so that when we encounter a rogue real number it gets promoted to a dual with a 0 value infinitesimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042a815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convert (generic function with 196 methods)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.promote_rule, Base.convert\n",
    "promote_rule(::Type{Dual}, ::Type{<:Number}) = Dual\n",
    "convert(::Type{Dual}, x::Real) = Dual(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf51c08",
   "metadata": {},
   "source": [
    "Now we want to encode our differentation rules. They are fairly simple:\n",
    "\n",
    "$(f+g)'(x) = f'(x) + g'(x)$\n",
    "\n",
    "$(f-g)'(x) = f'(x) + g'(x)$\n",
    "\n",
    "$(f*g)'(x) = f(x)*g'(x) + f'(x)*g(x)$\n",
    "\n",
    "$(f/g)'(x) = (f'(x)*g(x) - f(x)*g'(x))/g(x)^2$\n",
    "\n",
    "To translate into our Dual numbers we look back at the Taylor expansion and see that when we apply a function to a number the regular part of its Dual number is the function value and the infinitesmial part is the the derivative of the function at that point. Therefore, to translate these we simply need to overload the operators for our +, -, \\*, and / functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1acb64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base.+, Base.-, Base.*, Base./;\n",
    "+(x::Dual, y::Dual) = Dual(x.n + y.n, x.d + y.d);\n",
    "-(x::Dual, y::Dual) = Dual(x.n - y.n, x.d - y.d);\n",
    "*(x::Dual, y::Dual) = Dual(x.n * y.n, x.d * y.n + y.d * x.n);\n",
    "/(x::Dual, y::Dual) = Dual(x.n / y.n, (x.d * y.n - y.d * x.n) / y.n^2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a4203a",
   "metadata": {},
   "source": [
    "Those rules look very similar to the differentation rules outlined above (and painstakingly derived) many years ago. Let's see if it works. Let's define the function $f(x) = x^2$ and pass it a dual number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6c1d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = x * x\n",
    "f(Dual(2.0, 1.0)).d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987634f5",
   "metadata": {},
   "source": [
    "Wow! That worked really well. However, that was a perculiar way to define the square function especially when the power operator exists in the Julia language. Let's try defining the function as we normally would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0501773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2(x) = x^2\n",
    "f2(Dual(2.0, 1.0)).d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b0588",
   "metadata": {},
   "source": [
    "Almost too good to be true! Let's define the ``sin`` function using a Taylor series recalling that the derivative of ``sin`` is ``cos``. First we will check that our approximation of ``sin`` works by regularly sampling in the range [0,pi] and checking against the Julia implementation to see if it is within machine precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c451de0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sin_taylor(x)\n",
    "    res = 0\n",
    "    for n = 1:2:20\n",
    "        p = mod((n - 1) / 2, 2)\n",
    "        res += (-1)^p * x^n / factorial(n)\n",
    "    end\n",
    "    return res\n",
    "end\n",
    "\n",
    "all(sin_taylor.(0:0.01:pi/2) .- sin.(0:0.01:pi/2) .< 10^-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81277222",
   "metadata": {},
   "source": [
    "That worked pretty well, so our Taylor series is working accurately. Now, let's see what happens if we pass a dual number to it and inspect the derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2479dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067811865475"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin_taylor(Dual(pi/4,1)).d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a23d4",
   "metadata": {},
   "source": [
    "That looks very close to the expected value of $\\frac{\\sqrt{2}}{2}$. Let's check the against the standard result across an entire range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd52bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(getfield.(sin_taylor.(Dual.(0:0.01:pi/2,1)), :d) .- cos.(0:0.01:pi/2).< 10^-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b168f",
   "metadata": {},
   "source": [
    "Remarkably, we have gotten the derivative *for free*. We didn't really need to define any special code, we simply needed to define the rules of differentation to the dual numbers. Those differentation rules can be extended to include the analytical functions: ``sin``, ``cos``, and ``exp``. They can also be extended to include any special function provided we know how differentiation works. It can then be guarenteed to work on *any* composite function automatically. This method of differentation is known as *automatic differentation*. What is remarkable about it is that it gives arbitrary precision (i.e. the *correct* derivative) for any function that we can define with standard operations (which is basically all of them, for scientific purposes) in the time it takes to run the function itself. It is therefore as accurate as symbolic differentation and as quick as numeric differentation.\n",
    "\n",
    "This remarkable result has been the backbone of efficient gradient calculation and has been tremendously useful in the field of machine learning: it allows us to compute derivatives for *extremely* complicated functions very efficiently. There are technically two methods of automatic differentation: forward mode and reverse mode. We exmained forward mode and it was coded in about 8 lines of Julia! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c750c9",
   "metadata": {},
   "source": [
    "## 4 Performant Code\n",
    "\n",
    "Generally, Julia is flexible enough that our code will compile provided it makes sense. For most cases, examples are small enough and Julia performant enough that programmers dont need to apply \"tricks\" to make it run faster. However, in scientific programming we often find ourselves working with long running algorithms (think constructing a genome *de novo* or running an MCMC simulation) and it would benefit us to write our code in a way that is beneficial to the compiler. Doing so can save a lot of time.\n",
    "\n",
    "\n",
    "### 4.1 Quick performance: @simd and @inbounds\n",
    "\n",
    "In the first notebook we compared the difference between vectorised code and a simple ``for`` loop for perfoming a matrix calculation. We found that there wasn't a significant difference and oftentimes, for flexibility (and perhaps readability), it is better to use the ``for`` loop (note: this isn't always the case, a vectorised format lends itself *very* well to readability in Linear Algebra tasks). Let's remind ourselves of that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "vec_a = rand(100)\n",
    "mat_a = rand(100, 100)\n",
    "\n",
    "function matmul_test(mat, vec)\n",
    "    tmp = zeros(size(mat)[1])\n",
    "    for j = 1:size(mat)[1]\n",
    "        for i = 1:size(mat)[2]\n",
    "            tmp[i] += vec[j] * mat[i, j]\n",
    "        end\n",
    "    end\n",
    "    return tmp\n",
    "end\n",
    "\n",
    "# check they give the same result to within machine precision\n",
    "println(sum(mat_a * vec_a - matmul_test(mat_a, vec_a)) < 1e-7)\n",
    "\n",
    "@btime mat_a * vec_a;\n",
    "@btime matmul_test(mat_a, vec_a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077aa964",
   "metadata": {},
   "source": [
    "#### @simd\n",
    "First, a note on \"vectorisation\": in computer science application vectorisation doesn't necessarily refer to vectors. Often it refers to a SIMD routine: single instruction multiple data. At a low processing level this means that if the data is arranged in a list a single clock cycle can operate on multiple elements of the list simultaneously offering a speed up. In vectorised code this is naturally the case and languages like R exploit these SIMD routines to off a speed up. In Julia we can activate SIMD routines with the ``@simd`` macro. Let's see what it does for our ``matmul_test`` code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3776124b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @btime not defined\nin expression starting at In[23]:10",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @btime not defined\nin expression starting at In[23]:10",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "function matmul_test_simd(mat, vec)\n",
    "    tmp = zeros(size(mat)[1])\n",
    "    @simd for j = 1:size(mat)[1]\n",
    "        for i = 1:size(mat)[2]\n",
    "            tmp[i] += vec[j] * mat[i, j]\n",
    "        end\n",
    "    end\n",
    "    return tmp\n",
    "end\n",
    "@btime matmul_test(mat_a, vec_a);\n",
    "@btime matmul_test_simd(mat_a, vec_a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db51c46",
   "metadata": {},
   "source": [
    "There is a performance increase! Although, it's quite marginal. SIMD routines may offer more or less peformance in different code settings and are actually not desirable in some instances. This is because they work by reordering some operations and at a very low level even mathematically commutative operations will have different results when reordered due to numerical considerations. These concerns may affect high performance numerically unstable code and so it is good to be aware of - for most basic codes they are not a concern.\n",
    "\n",
    "#### @inbounds\n",
    "In the ``for`` loop implementation we found ourselves accessing into data with an index. Julia acts like an interpreted language at the high level and helps us out by doing bounds-checks: it will tell us when we try and access an index that is outside of the arrays memory. More performant languages like C will not provide this convenience and will compile the code anyway - even though it will definitely give the wrong answer. Let's see what happens when we accidentally go out of bounds: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15d0f790",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 100-element Vector{Float64} at index [101]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 100-element Vector{Float64} at index [101]",
      "",
      "Stacktrace:",
      " [1] getindex",
      "   @ ./array.jl:924 [inlined]",
      " [2] matmul_test_oob(mat::Matrix{Float64}, vec::Vector{Float64})",
      "   @ Main ./In[24]:5",
      " [3] top-level scope",
      "   @ In[24]:10",
      " [4] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "function matmul_test_oob(mat, vec)\n",
    "    tmp = zeros(size(mat)[1])\n",
    "    for j = 1:(size(mat)[1]+1)\n",
    "        for i = 1:size(mat)[2]\n",
    "            tmp[i] += vec[j] * mat[i, j]\n",
    "        end\n",
    "    end\n",
    "    return tmp\n",
    "end\n",
    "matmul_test_oob(mat_a, vec_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec277eb4",
   "metadata": {},
   "source": [
    "Julia gives us a nice BoundsError with an error message telling us precisely what went wrong. This is an easy fix! This bounds checking is more work for the compiler and adds a significant overhead to compile time. Sometimes we are confident that we *are* in bounds and would like to let the compiler know to not do all that additional work. For this we use the ``@inbounds`` macro. It is applied to the outermost loop and immediately gets pushed through any inner loops, but it only applies to a single loop block. Let's try it out on the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb52ae32",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @btime not defined\nin expression starting at In[25]:10",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @btime not defined\nin expression starting at In[25]:10",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "function matmul_test_inbounds(mat, vec)\n",
    "    tmp = zeros(size(mat)[1])\n",
    "    @inbounds for j = 1:size(mat)[1]\n",
    "        for i = 1:size(mat)[2]\n",
    "            tmp[i] += vec[j] * mat[i, j]\n",
    "        end\n",
    "    end\n",
    "    return tmp\n",
    "end\n",
    "@btime matmul_test(mat_a, vec_a);\n",
    "@btime matmul_test_inbounds(mat_a, vec_a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e48135",
   "metadata": {},
   "source": [
    "That is a substantial performance gain! In fact, the gain is so large that we might be tempted to *always* use the @inbounds macro. This is generally not recommended because it is very easy to make mistakes in development. Just as with insisting on specific data types to avoid mutation, it is better to write high level code without performance macros and activate them when we are confident that everything is working. For example, the following code is wrong but \"looks fine\" and with ``@inbounds`` will compile. Good luck spotting this error in a codebase with 1000s of lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ffee3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "function matmul_test_oob_unsafe(mat, vec)\n",
    "    tmp = zeros(size(mat)[1])\n",
    "    L = size(mat)[1] + 1\n",
    "    @inbounds for j = 1:L\n",
    "        for i = 1:L\n",
    "            tmp[i] += vec[j] * mat[i, j]\n",
    "        end\n",
    "    end\n",
    "    return tmp\n",
    "end\n",
    "matmul_test_oob_unsafe(mat_a, vec_a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78854e01",
   "metadata": {},
   "source": [
    "Finally, the ``@simd`` and ``@inbounds`` macros can be combined for maximum peformance. The ``@simd`` macro should be applied before the ``@inbounds`` macro. Let's compare this optimised code against our original implementations and see a substantial increase even beating out the vectorised code (and creaming R and Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8aec3f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @btime not defined\nin expression starting at In[27]:10",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @btime not defined\nin expression starting at In[27]:10",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "function matmul_test_unsafe_fast(mat, vec)\n",
    "    tmp = zeros(size(mat)[1])\n",
    "    @inbounds for j = 1:size(mat)[1]\n",
    "        @simd for i = 1:size(mat)[2]\n",
    "            tmp[i] += vec[j] * mat[i, j]\n",
    "        end\n",
    "    end\n",
    "    return tmp\n",
    "end\n",
    "@btime mat_a * vec_a;\n",
    "@btime matmul_test(mat_a, vec_a);\n",
    "@btime matmul_test_unsafe_fast(mat_a, vec_a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201f86e",
   "metadata": {},
   "source": [
    "## 4.2 Data Access Patterns\n",
    "\n",
    "Something that is not often thought about is how data is laid out in memory. In general, random access memory is linear while matrices are two dimensional: how do we decide which memory address each matrix element (and indeed higher order tensor elements) goes to? It turns out that different languages choose different conventions. In C and Python each of the *rows* is laid out contiguously so for column elements from the same row are found next to each other in memory:\n",
    "\n",
    "`` (row-major) mat_addresses: [ 1 2 3\n",
    "                              4 5 6 ]\n",
    "``\n",
    "\n",
    "Julia (and most scientific languages such as R, MatLab, and Fortran) lays out memory in *columns* so that row elements in the same column are found next to each other in memory:\n",
    "\n",
    "`` (column-major) mat_addresses: [ 1 3 5\n",
    "                                 2 4 6]\n",
    "``\n",
    "\n",
    "We say that Julia is a *column-major* ordered language while C is a *row-major* ordered language. There is endless debate about which is better but both have their advantages and disadvantages. Why do we need to be aware of these differences? For the computation result it doesn't matter if you access rows first or columns first, but for the computation time it can have a serious impact. This is because if you leave the fastest varying index on the columns in a column major language the memory access becomes difficult: we have to make strides in memory locations to find the data we are looking for. Therefore, it is better to fix the column and vary through the rows because these are all close to each other. This would be the reverse in a row-major language. Compare the following two functions: one accesses an entire column at a time, the other an entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41dc7e9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @btime not defined\nin expression starting at In[28]:19",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @btime not defined\nin expression starting at In[28]:19",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "function column_access(a);\n",
    "    res = 0;\n",
    "    for j = 1:size(a)[2]\n",
    "        res += sum(a[:,j] * j)\n",
    "    end\n",
    "    return res\n",
    "end\n",
    "\n",
    "function row_access(a);\n",
    "    res = 0;\n",
    "    for i = 1:size(a)[1]\n",
    "        res += sum(a[i,:] * i)\n",
    "    end\n",
    "    return res\n",
    "end\n",
    "\n",
    "a = ones(10000, 10000);\n",
    "\n",
    "@btime row_access(a);\n",
    "@btime column_access(a);\n",
    "# Check that they are the same result\n",
    "row_access(a) == column_access(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab897f",
   "metadata": {},
   "source": [
    "They both computed the same result, but one was substantially faster than the other. The general best-practice data access pattern is to take the slow-varying index in the outer-most loop and the fast-varying index in the inner-most loop. The pattern for Julia, therefore, is to access our columns in the outer for loop, and the rows in the inner for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b007a",
   "metadata": {},
   "source": [
    "### 4.3 Global vs Local Workspaces\n",
    "\n",
    "Julia has two notions of workspace. A global workspace and a local workspace. The global workspace is any variable and function definition in the REPL or (more usually) in your script and not wrapped by a function. Local workspaces are those in functions and modules. The global workspace has some penalty performances asscociated with it and good working practice is to put all of your code into functions. This saves you time in two ways: 1) development time by making it more readable, organised, and easier to come back to, 2) compilation time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504d53f",
   "metadata": {},
   "source": [
    "# Moving Forward\n",
    "\n",
    "By now we have a fairly advanced idea about what Julia is, what its capabilities are and why we may use it preferrentially, how to interact with it, and some advanced ideas to make our code flexible and performant. We are capable Julians when it comes to writing generic Julia code! There are still some basic concepts that would greatly benefit us as Data Scientists and these have been arranged into several notebooks: plotting, data and statistics, and high performance computing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
